{
    "collab_server" : "",
    "contents" : "---\ntitle: \"AXAML Session 1 Live Demo & Practice\"\nauthor: \"David Sultan\"\noutput:\n  html_notebook: default\n---\n\nThis notebook is based on the documentation included in AXAML package.\n\n#Installing and loading packages\n\n```{r, include=FALSE}\nlibrary(devtools)\ndevtools::install_github(\"ds4a/axaml\",\n                         ref = \"Hackathon2017\",\n                         host = \"github.axa.com/api/v3\",\n                         username = Sys.getenv(\"ghe.user\"), #PassAXA e-mail\n                         auth_token = Sys.getenv(\"ghe.pass\") #GHE token\n                         )\n\n```\n\n# Checking out the package documentation\n\nWe can obtain information about the **axaml** package or a particular function simply by typing its name in the R console:\n\n```{r}\n## example\n?axaml::stats\n```\n<br/>\n\n# Setting up the environment and dataset\n\n## Loading axaml\n\n```{r}\nlibrary(axaml)\n#loadNamespace('printr')\n\n```\n\n## Loading the dataset\n\nIn this example, we will use the example portoflio dataset that comes with the axaml package.\n\n```{r}\n#DATA = read.csv(\"path/to/your/data.csv\")\ndt = portfolio_example\n#data.axaml(dt)\n```\n\n## Taking a quick look at the dataset\n\n```{r}\nhead(dt,100)\n```\n\n\n## Setting the special attribute names\n\n**Exercise** : display the documentation about the \"spattr\" function\n```{r, echo=TRUE}\n# Your code here\n```\n\n\nWe need to define special attributes for the dataset: exposure, claimcount, claimcost, ... Any special attribute can be defined. \nThis allows special functions to know which variables to act on, without having to rename directly the variables in the dataset, or giving the variable name as an argument each time we call the function.\n\n```{r}\n#set_attributes(DT = dt, exposure = \"Exposure\", claimcount = \"Numtppd\", claimcost = \"Indtppd\")\nspattr(DT = dt, exposure = \"Exposure\", claimcount = \"Numtppd\", claimcost = \"Indtppd\")\n```\n\n#Exploring Data \n\n## Getting descriptive statistics on the dataset\n\nThe **stats()** function is used to compute descriptive statistics on the portfolio dataset. It will automatically detect the available special attributes and calculate all descriptive statistics related.\n<br/>\nIn the following example, as claimcount and exposure are defined, we get the overall frequency on the dataset among other things.\n```{r}\nst1 = stats(DT = dt)\nst1\n```\n\nWe can also get these statistics for particular variables of the dataset, by setting the argument *varnames*\n```{r}\nst2 = stats(DT = dt, varnames = c(\"Occupation\", \"Type_Car\"))\nst2$Occupation\nst2$Type_Car\n```\n\nFinally, we can get a custom ordering for your statistics table, by giving the order_by and order arguments. In this example, we would like to order the stats table by decreasing total exposure.\n\n```{r}\nst2 = stats(DT = dt, \n            varnames = c(\"Occupation\", \"Type_Car\"), \n            order_by = \"exposure\", \n            order = -1)\n\nst2$Occupation\n```\n\n## Visualizing the statistics\n\nYou can visualize the statistics related to frequency of claim cost using function **plotter**:\n\n```{r}\n#plt1 = plotfreq(st2)\nplt1 <- plotter(st2, x = \"levels\",  bar = \"exposure\", line = \"freq\")\n#\nplt1$Occupation\n```\n\nYou can also visualize the statistics related to claim average cost using function **plotter**:\n```{r}\nplt2 <- plotter(st2, x = \"levels\",  bar = \"nbclaims\", line = \"avgcost\")\nplt2$Type_Car\n```\n\n**Exercise** : plot the pure premium by occupation (exposure with bars, pure premium with a line) and save it in a `plt3` object\n```{r, echo=TRUE}\n# Your code here\n```\n\n\nYou can also display any other statistics with this **plotter()** function.\nIn this example we add a Premium variable to the dataset, and want to visualize the loss ratio per Age (cost / earned premium).\n```{r}\n## adding a fake premium\ndt$Prem = 500\nspattr(dt, premium = \"Prem\")\n\nst3 = stats(DT = dt, varnames = c(\"Age\"))\n\nhead(st3$Age)\n\nplt3 = plotter(st3, bar = \"exposure\", line = \"lossratio\")\nplt3$Age\n```\n\n\n## Training a GLM model\n\nWe are going to use the **glmodel()** function. Under the hood, it uses R's base **glm()** function. The main benefit is that specifying the base level you would like to use is easier (by default the glmodel uses the level with the highest exposure as base level).\n\n```{r}\nmodel_features <- c(\"Occupation\", \"Bonus\", \"Age\", \"Type_Car\")\n\nmod1 = glmodel(DT = dt, \n               predictors = model_features, \n               target = \"Numtppd\", \n               family = poisson(\"log\"))\n```\n\nWe can modify this behaviour by providing the *base_levels* argument. In this example, we change the base level from *Occupation* to *Housewife*.\n\n```{r}\nmod2 = glmodel(DT = dt, \n               predictors = model_features, \n               target = \"Numtppd\", # /!\\ name of the target in dt (not \"claimcount\" special attribute)\n               family = poisson(\"log\"), \n               base_levels = list(Occupation = \"Housewife\"))\n```\n\n## Visualizing the results of the GLM model\n\nNext we take a look at the relative frequency fit of this last model.\n\n```{r, warning=FALSE}\nst4 = stats(DT = dt, \n            varnames = c(\"Occupation\"), \n            base_levels = list(Occupation = \"Housewife\"), \n            model = mod2)\nst4$Occupation\npltrel1 = plotter(st4, \n                  bar = \"exposure\", \n                  line = c(\"freq_rel\",\n                              \"freq_pred_rel\",\n                              \"freq_mdl_rel\",\n                              \"freq_mdl_rel_p2se\",\n                              \"freq_mdl_rel_m2se\"))\npltrel1$Occupation\n```\n\nCan it be simpler to generate this kind of plot?\n\nYes, the function **plotfreqrel()** has been added to do it with less code and with a nicer plot.\n\n```{r, echo=TRUE}\n\n\npltrel2 = plotfreqrel(st4)\n\npltrel2$Occupation\n```\n\n**Exercise** : Plot the relative frequency fits for each one of the 4 features of the `mod2` model \n```{r, echo=TRUE}\n# your code here\n\n```\n\n\n\n#Correlations Visualization\n\n```{r}\ncr =correl(DT = dt, \n           vars = model_features, \n           type = \"cramersV\")\n\nplot_correlation(cr$corr_mat\n                 #, corr_thresh = 0.2\n                 )\n\n```\n\nThe correlations circle could be easier to use. Let's add a threshold to keep only the features pairs with correlation > 0.15 :\n\n```{r}\nplot_correlation(cr$corr_mat,\n                 corr_thresh = 0.15\n                 )\n```\n\n# Time consistency\n\n```{r}\ntc <- consist(DT = dt, \n              elements  = c(\"freq_rel\"),  \n              varnames = \"Occupation\", \n              cvar = \"CalYear\")\n\npc <- plotconsist(tc)\npc\n```\n\nInteractive Addin\n\n```{r, eval=FALSE, include=TRUE}\ntc_all <- consist(DT = dt, \n              elements  = c(\"freq\",\"freq_rel\",\"avgcost\"),  \n              varnames = model_features, \n              cvar = \"CalYear\")\nconsistAddin(tc_all)\n```\n\nUsing this addin to check some ideas of interactions?\n```{r, eval=FALSE, include=TRUE}\ntc_interact <- consist(DT = dt, \n              elements  = c(\"freq\",\"freq_rel\",\"avgcost\"),  \n              varnames = model_features, \n              cvar = \"Gender\")\nconsistAddin(tc_interact)\n```\n\n",
    "created" : 1507206829895.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3312436367",
    "id" : "50B9334",
    "lastKnownWriteTime" : 1507206829,
    "last_content_update" : 1507206829,
    "path" : "/private/var/folders/97/8wdmwr7x0tbcvr1bfw1bds0m0000gn/T/com.microsoft.Outlook/Outlook Temp/axaml_live_demo[16].Rmd",
    "project_path" : null,
    "properties" : {
        "chunk_output_type" : "inline"
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}
{
    "collab_server" : "",
    "contents" : "library(keras)\n\n\n\nlibrary(data.table)\nlibrary(glmnet)\nlibrary(gbm)\nlibrary(xgboost)\nlibrary(tidyverse)\ndb=rbind(cbind(fread(\"train.csv\"),train=1),cbind(fread(\"test.csv\"),SalePrice=1,train=0))\nvar_useless=c(\"Id\",\"train\")\n\n# char=>factor\ndb <- db %>%\n  mutate_if(sapply(db, is.character), as.factor)\n\n# NA as a level\ndb <- db %>% \n  mutate_if(sapply(db, is.factor), addNA)\n\n# scale numeric\nscale_vec <- function(x){\n  c(scale(x))\n}\nnums <- names(sapply(db,is.numeric))\ndb <- db%>%\n  mutate_if(setdiff(nums,c(\"train\",\"SalePrice\")),scale_vec)\n\nsum(sapply(db,function(x)sd(x)==1)) #no numerical constant\nmin(sapply(db,function(x)length(levels(factor(x))))) # no factor constant\n\n#in this dbset, NA actually means \"there isn't\", not \"we don't know\"...\nNAs <- sapply(db,function(x)sum(is.na(x))/nrow(db))\nNAs <- NAs[NAs>0]\nsapply(db[,names(NAs)],summary)\n\n#LotFrontage NA is none => 0\ndb[is.na(db$LotFrontage),]$LotFrontage <- 0\n#MasVnrArea NA is none => 0\ndb[is.na(db$MasVnrArea),]$MasVnrArea <- 0\ndb[is.na(db$BsmtHalfBath),]\nfor (nm in setdiff(names(NAs),names(db)[grep(pattern=\"Yr\",x = names(db),ignore.case = T)])){\n  print(nm)\n  db[is.na(db[[nm]]),nm]<-0\n}\nlibrary(Hmisc)\ndb$GarageYrBlt_cut=addNA(cut2(db$GarageYrBlt,g = 10))\ndb=within(db,rm(GarageYrBlt))\n\nsample_gbm=sample(1:sum(db$train),round(.5*sum(db$train)))\n\n\n\n# db$SalePrice=log(db$SalePrice)\n\ndb_matrix=model.matrix(~.,data = db)\n\n\nsample_train=sample(1:sum(db$train),round(.7*sum(db$train)))\nlabeled_data=db_matrix[db_matrix[,\"train\"]==1,]\ntrain=labeled_data[sample_train,] #CAREFUL rows with NAs are removed https://stackoverflow.com/questions/6447708/model-matrix-generates-fewer-rows-than-original-data-frame\n\nx_train <- train[,setdiff(colnames(train),\"SalePrice\")]\ny_train <- train[,\"SalePrice\"]\ntest <- labeled_data[-sample_train,]\nx_test <- test[,setdiff(colnames(test),\"SalePrice\")]\ny_test <- test[,\"SalePrice\"]\n\nrm(model)\ngc()\nbatch_size <- 32\nepochs <- 1000\n# without batch norm ~0.15 MSE, with layer_batch_normalization() on 1st layer of 300-80-20-80-100-1. ~0.05773317 MSE ! https://arxiv.org/abs/1502.03167 \n# batch norm on 2nd layer ~0.04984472 of 300-80-20-80-100-1. On 3rd layer 0.05692367. \n# don't put norm at each layer ! it won't converge. Don't put the batchNorm at the end 0.1243595, same as no norm.\n# layer_alpha_dropout(object, rate, noise_shape = NULL, seed = NULL) self normalizing neural nets https://arxiv.org/abs/1706.02515\nmodel <- keras_model_sequential()\nbuild_model <- function(){\nmodel %>%\n  layer_dense(units = 300, input_shape = ncol(x_train)) %>% \n  layer_activation(activation = 'relu') %>% \n  layer_batch_normalization()%>%\n  layer_dropout(rate = 0.1) %>% \n    \n  layer_dense(units = 80) %>% \n  layer_activation(activation = 'relu') %>% \n  layer_batch_normalization()%>%\n  layer_dropout(rate = 0.3) %>% \n    \n  layer_dense(units = 20) %>% \n  layer_activation(activation = 'relu') %>%\n  # layer_batch_normalization()%>%\n  layer_dropout(rate = 0.5) %>% \n    \n  layer_dense(units = 80) %>% \n  layer_activation(activation = 'relu') %>% \n  # layer_batch_normalization()%>%\n  layer_dropout(rate = 0.5) %>% \n    \n  layer_dense(units=100) %>% \n  layer_activation(activation = 'relu') %>% \n  # layer_batch_normalization()%>%\n  layer_dropout(rate = 0.2) %>% \n    \n  layer_dense(units=1)%>%\n  layer_activation(activation = 'linear')\n\nmodel %>% compile(\n  loss = 'mean_squared_error',\n  optimizer = 'adam',#try also sgd \n  metrics = c('mean_squared_error')\n)\n\nhistory <- model %>% fit(\n  x_train, y_train,\n  batch_size = batch_size,\n  epochs = epochs,\n  verbose = 2,\n  validation_split = 0.1\n)\n\nscore <- model %>% evaluate(\n  x_test, y_test,\n  batch_size = batch_size,\n  verbose = 1\n)\n\nprint(score)\n}\nbuild_model()\n\n\n\n\n",
    "created" : 1507211757153.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "77|26|128|0|\n",
    "hash" : "605854986",
    "id" : "7303DE1",
    "lastKnownWriteTime" : 1507296086,
    "last_content_update" : 1507296090621,
    "path" : "~/Documents/HousePrices/keras.R",
    "project_path" : "keras.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}